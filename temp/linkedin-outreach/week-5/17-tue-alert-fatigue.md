# Post #17: Alert Fatigue is Killing Your Team
**Week 5 | Tuesday | 7:00 AM PT**
**Format:** Text Post
**Blog Link:** Alerting

---

## POST CONTENT (Copy everything below the line)

---

3 AM. Phone buzzes.

Then buzzes again.
And again.
17 alerts.

15 are noise.
2 are duplicates.
The real problem? Already self-healed.

You're wide awake.
Sleep isn't coming back.
Tomorrow's meeting? That's going to be rough.

ğ—§ğ—µğ—¶ğ˜€ ğ—¶ğ˜€ ğ—®ğ—¹ğ—²ğ—¿ğ˜ ğ—³ğ—®ğ˜ğ—¶ğ—´ğ˜‚ğ—².

And it's worse than no alerts at all.

Why? Because your team learns to ignore alerts.
When the real incident comes, it gets lost in the noise.

ğ—§ğ—µğ—² ğ—³ğ—¶ğ˜…:

Every alert must answer YES to ALL of these:
âœ“ Does this require immediate human action?
âœ“ Is the impact clear and significant?
âœ“ Can the responder actually do something?
âœ“ Would I be okay being woken up for this?

If not? It's not an alert. It's noise.

ğ—§ğ—®ğ—¿ğ—´ğ—²ğ˜: < 2 pages per on-call shift

What's your alert-to-incident ratio?

---
#Alerting #OnCall #SRE #DevOps

ğŸ’¡ Alert best practices guide in comments

---

## FIRST COMMENT (Post within 60 seconds)

ğŸ“š I wrote a complete guide on alerting - what to alert on, how to reduce noise, and SLO-based alerting:

https://blog.shivam.info/docs/observability/alerting?utm_source=linkedin&utm_medium=social&utm_campaign=week5

Key sections:
â†’ The 4-question alert test
â†’ Alert severity levels
â†’ Grouping and deduplication
â†’ Runbook requirements
â†’ On-call health metrics

We deleted 60% of our alerts. Incidents got resolved faster.

---

## ALTERNATIVE HOOKS

**Alt 1:** "We deleted 60% of our alerts. Incidents got resolved FASTER."

**Alt 2:** "17 alerts. 15 were noise. Sound familiar?"

**Alt 3:** "Alert fatigue killed our incident response. Here's how we fixed it."

---

## ENGAGEMENT TIPS

- Highly relatable - everyone has alert fatigue stories
- Ask: "What's the most useless alert you've seen?"
- Discuss the cultural challenge of deleting alerts
- Share your own "we deleted X alerts" success stories
